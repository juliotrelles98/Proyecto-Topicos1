{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-31fd3cdf456a>, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-31fd3cdf456a>\"\u001b[1;36m, line \u001b[1;32m66\u001b[0m\n\u001b[1;33m    cnn.add(MaxPooling2D(pool_size=tamano_pool))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys ##librerias para moverse en el sistema operativo\n",
    "import os ##librerias para moverse en el sistema operativo\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator ## preprocesar imagenes\n",
    "from tensorflow.python.keras import optimizers ##optimizadora para entrear nuestro CNN*/\n",
    "from tensorflow.python.keras.models import sequential           ##libreria de redes secuenciales\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten,Dense,Activation \n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D \n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "K.clear_sesion()\n",
    "\n",
    "data_entrenamiento= 'C:\\Users\\Julio Trelles\\Desktop\\Proyecto Topicos\\data\\entrenamiento'\n",
    "data_validacion= 'C:\\Users\\Julio Trelles\\Desktop\\Proyecto Topicos\\data\\validacion'\n",
    "\n",
    "Epocas= 20 ## numero de veces iteracion sobre el set de entrenamiento \n",
    "altura, longitud= 100,100 ##cambio de tama単o de imagenes\n",
    "bacth_size= 32 ##Numero de imagenes para procesar en cada uno de los pasos\n",
    "pasos=1000 ## numero de veces que se va procesar la informacion\n",
    "pasos_validacion=200 ## ver su esta aprendiendo nuestra cnn\n",
    "filtrosConv1=32 ## profundidad de imagen de 32\n",
    "filtrosConv2=64 ## profundida de imagen de 64\n",
    "tamano_filtro1= (3,3) ## tama単o de filtro\n",
    "tamano_filtro2= (2,2) ## tama単o de filtro\n",
    "tamano_pool=(2,2) ## tama単o de filtro de Maxpooling\n",
    "clases=1\n",
    "lr=0.0005 ## ratio de aprendimiento\n",
    "\n",
    "##pre procesamiento de imagenes de nuestra CNN\n",
    "\n",
    "entrenamiento_datagen= ImageDataGenerator(\n",
    "   rescale= 1./255, ## re escaldo de imagenes el rango de los pixeles\n",
    "   shaer_range=0.3, ## inclinar las imagenes para mejor aprendizaje\n",
    "   zoom_range=0.3, ## zoom a algunas imagenes \n",
    "   horizontal_flip= True ## invertir la imagen\n",
    ")\n",
    "\n",
    "validacion_datagen=ImageDataGenerator(\n",
    "   rescale= 1./255, ## re escaldo de imagenes el rango de los pixeles\n",
    ")\n",
    "\n",
    "entrenamiento_imagen= entrenamiento_datagen.flow_from_directory(\n",
    "   data_entrenamiento,\n",
    "   target_size=(altura, longitud),\n",
    "    batch_size= batch_size,\n",
    "    class_mode='categorical'\n",
    "\n",
    ")\n",
    "\n",
    "valdiacion_imagen= validacion_datagen.flow_from_directory(\n",
    "   data_validacion,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size= batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "##RED CNN\n",
    "\n",
    "cnn=Sequential()\n",
    "\n",
    "cnn.add(Convolution2D(filtroConv1, tamano_filtro1, padding='same', input_shape=(altura,longitud,3), activation='relu')) ## primera capa de convolucion\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "cnn.add(Convolution2D(filtroConv2, tamano_filtro1, padding='same',activation='relu') ## segunda capa convulucional \n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "           \n",
    "cnn.add(faltten())    ## contiene todo la info de la cnn en una sola dimension\n",
    "cnn.add(Dense(256,activation='relu'))  ## neuronas conectadas con la capa flatten\n",
    "cnn.add(Dropout(0.5)) ## evitar sobreajuste apagando el 50% de la neuronas\n",
    "cnn.add(Dense(clases),activation='softmax') ## softmax = es probabilidad\n",
    "        \n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=optimimizer.Adam(lr=lr), metrics=['accuracy']) ##optimizacion\n",
    "\n",
    "cnn.fit(entrenamiento_imagen, steps_per_epoch=pasos, epochs=epocas, validation_data=validacion_imagen, valitadtion_steps=pasos_validacion)\n",
    " \n",
    "direc='./modelo/'\n",
    "        \n",
    "if not os.path.exists(direc):\n",
    "        os.mkdir(direc)\n",
    "cnn.save('./modelo/modelo.h5') ## save de estructura de modelo\n",
    "cnn.save_weihgts('.modelo/pesos.h5')        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
